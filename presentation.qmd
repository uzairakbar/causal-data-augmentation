---
title: Symmetry as Intervention
subtitle: |
  An Analysis of Causal Effect Estimation using<br>Outcome Invariant Data Augmentation
  <span style="float: right;">[arXiv:2510.25128](https://arxiv.org/abs/2510.25128)</span>
format:
  metropolis-beamer-revealjs:
    theme: style.scss
    embed-resources: true
    controls: true
    controls-layout: bottom-right
    navigation-mode: linear
    html-math-method: mathjax
    include-in-header:
      - file: "macros.jax"
      - text: |
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
header-logo: images/neurips-logo.svg
header-logo-link: "https://neurips.cc/virtual/2025/loc/san-diego/poster/119327"
slide-number: "c"
author:
  - name: Uzair Akbar
    affiliations: Georgia Tech
    orcid: 0009-0001-7826-3578
  - name: Niki Kilbertus
    affiliations: TU Munich
    orcid: 0000-0001-8718-4305
  - name: Hao Shen
    affiliations: TU Munich
    orcid: 0000-0003-0091-4155
  - name: Krikamol Muandet
    affiliations: CISPA
    orcid: 0000-0002-4182-5282
  - name: Bo Dai
    affiliations: Georgia Tech
    orcid: 0009-0002-8070-574X
date: last-modified
bibliography: references.bib
embed-resources: true
---



# Motivation

## Correlation vs. causation


![[xkcd.com/925](https://xkcd.com/925/) by Randall Munroe.](https://imgs.xkcd.com/comics/cell_phones.png){style="image-rendering: auto;"}

::: {.incremental}
- Can we recover causal effects from *observational* data?
- **Yes—but only with untestable assumptions and domain knowledge!**
:::

## This work

<br><br><br>We try to answer the fundamental question:<br>

::: {.fragment}
> Can knowledge of **symmetries in data generation**—often used implicitly in certain regularizers—be repurposed to<br>**improve causal effect estimation** given<br>only observational $(X, Y)$ data?
:::

# Statistical vs. Causal Estimation

## Empirical risk minimization (ERM)
::: {.columns}
::: {.column width="80%"}
For *treatment* $X$, *outcome* $Y$ samples generated as
$$
Y = \rfunc{X} + \xi ,
\qquad
\E{\xi} = 0 ,
$$

::: {.fragment fragment-index="1"}
statistical inference entails recovering the *optimal predictor* $\E{ Y \mid X = \vx }$ [by minimizing the risk]{.fragment fragment-index="2"}
:::

::: {.fragment fragment-index="2"}
$$
R_{\ERM}( \bh ) := \E{ \sqNorm{ Y - \bhyp{X} } }  ,
$$
over hypotheses $\bh\in\H$, for a rich enough class $\H$.
:::

::: {.fragment}
For [un-correlated]{.highlight} $X$ and noise $\xi$, the ERM minimizer<br>
$\bh_{\ERM}{\blue{(}} \vx {\blue{)}}$ coincides with the true *causal* function $\rfunc{\vx}$.
:::
:::
::: {.column width="20%" .rightcol}
![](images/data-generation.svg){width=100% style="float:right;"}
:::
:::






## Data augmentation

::: {.columns}
::: {.column width="80%"}

::: {.fragment fragment-index="1"}
For finite $n$ samples $\D := \{ (\vx_i, \vy_i) \}_{i=0}^n$, *regularization*<br>
techniques are used to mitigate estimation *variance*.
:::

::: {.fragment fragment-index="2"}
<br>E.g., *data augmentation (DA)* achieves this via multiple random augmentations $(\gG \vx_i, \vy_i)$ per sample in the risk
:::

::: {.fragment fragment-index="3"}
<br>$$
R_{\DA+\ERM}( \bh ) := \E{ \sqNorm{ Y - \bhyp{ \gG X } } } ,
\quad
\gG\sim \P_{ \gG } .
$$
:::
:::

::: {.column width="20%" .rightcol}

![](images/data-generation.svg){width=100% style="float:right;"}

::: {.fragment fragment-index="2"}
<!-- ![](images/data-augmentation.svg){width=120% style="float:right;"} -->
![](images/data-augmentation.svg){width=100% style="float:left; transform: scale(1.25); transform-origin: left right;"}
:::

:::
:::







## Confounding bias and spurious correlation
::: {.columns}
::: {.column width="80%"}

::: {.fragment}
[Problem with ERM:]{.alert} Generally, $X$ and $\xi$ are [correlated]{.highlight}.
:::

::: {.fragment}
This makes the ERM minimizer a biased estimator of $\rf$:
$$
\begin{align*}
Y &= \rfunc{X} + \xi ,\\
\nonumber
\Rightarrow \underbrace{\E{Y \mid X = \vx} }_{\text{ERM minimizer}} &= \rfunc{\vx} + \underbrace{\E{ \xi \mid X = \vx}}_{\text{confounding bias $\neq 0$}} .
\end{align*}
$$
:::

::: {.fragment}
This *spurious correlation* b/w $X$ and $\xi$ arises due to their unobserved common parents, called *confounders*.
:::
:::

::: {.column width="20%" .rightcol}
![](images/confounded-data-generation.svg){width=100% style="float:right;"}
:::
:::



## Intervention for causal estimation
::: {.columns}
::: {.column width="80%"}

::: {.fragment fragment-index="1"}
Removing correlation b/w $X$, $\xi$, requires an *intervention*[—explicitly assigning $X$ some independently sampled $\Xtilde$ [during data generation]{.highlight}, a.k.a. a *randomized control trial*:
$$
Y = \rfunc{\Xtilde} + \xi
$$]{.fragment fragment-index="2"}
:::

::: {.fragment fragment-index="3"}
Now, doing ERM on samples of $(Y, \Xtilde)$ recovers $\rf$.
:::

<!-- ::: {.fragment fragment-index="4"}
More broadly, intervention $=$ "surgically" modify [individual data generation components]{.highlight}.
::: -->

::: {.fragment fragment-index="5"}
[Problem:]{.alert} Often not possible to intervene on real systems.<br> We only have access to pre-collected *observational* data.
:::
:::

::: {.column width="20%" .rightcol}

![](images/confounded-data-generation.svg){width=100% style="float:right;"}

::: {.fragment fragment-index="2"}
![](images/intervention.svg){width=100% style="float:right;"}
:::

:::
:::




## Instrumental variables (IVs)
::: {.columns}
::: {.column width="100%"}
![](images/instrument.svg){width=18.4% style="float:right;"}

::: {.fragment}
To workaround interventions, use *instrument* $\gZ$ satisfying
:::

::: {.incremental}
1. treatment relevance $\gZ \nindep X$,
2. exclusion $\gZ\indep Y \mid X$,
3. un-confoundedness $\gZ \indep \xi$,
4. [outcome relevance]{.highlight} $Y \nindep \gZ$,
:::

::: {.fragment}
Conditioning the model on $\gZ$ gives us $\E{ Y \mid \gZ } = \E{ \rfunc{X} \mid \gZ }$,<br>[which can be solved for $\rf$ by minimizing the risk
$$
R_{\IV}( \bh ) := \E{ \sqNorm{ Y - \E{ \bhyp{X} \mid \gZ } } } .
$$]{.fragment}
:::

::: {.fragment}
[Problem:]{.alert} Instruments are scarce in most application domains.
:::

:::

:::










# Causal Estimation with Data Augmentaiton

## Data augmentation = model symmetries

::: {.fragment}
We restrict ourselves to DA transformations with respect to which $\rf$ is [*invariant*]{.highlight}. [Specifically, $\gG$ takes values in $\G$ such that $\rf$ is *$\G$-invariant*:
$$
\rfunc{\vx} = \rfunc{\vg \vx},
\qquad
\forall
\;\;
(\vx, \vg)\in \X\times\G .
$$]{.fragment}
:::

::: {.fragment}
Of course, constructing such DA requires knowledge of *symmetries* of $\rf$. [E.g., when classifying images $\vx\in\X$ of cats vs. dogs, the true labeling function would certainly be invariant to random image rotations $\gG\vx$.
![](images/catRotation.svg){width=90% style="float:center;"} ]{.fragment}
:::





## Data augmentation = soft intervention
::: {.row}
::: {.columns}
::: {.column width="60%"}
::: {.fragment fragment-index="1"}
**Key insight:** When $\rf$ is $\G$-invariant, $(Y, \gG X)$ follows the data generation: 
$$
Y = \rfunc{ \gG X } + \xi .
$$
:::
::: {.fragment fragment-index="2"}
Therefore, DA is equivalent to a *soft* intervention on the treatment $X$.
:::
:::
::: {.column width="40%" .rightcol}
::: {.fragment fragment-index="2"}
![](images/augmentation-intervention.svg){width=100% style="float:right;"}
:::
:::
:::
:::

::: {.row}
::: {.fragment fragment-index="3"}
$\Rightarrow$ DA+ERM [*dominates*]{.highlight} vanilla ERM on *causal estimation error (CER)*:
:::
<div class="fragment fade-in" data-fragment-index="3" style="position: absolute;">
<div class="fragment fade-out" data-fragment-index="4" style="position: absolute;">
$$
\CER(\bh) := \E{ \sqNorm{ \rfunc{X} - \bhyp{X} } } , 
\phantom{\qquad
\boxed{
  \CER(\bh_{\DA+\ERM}) \leq \CER(\bh_{\ERM})
} .}
$$
</div>
</div>
::: {.fragment fragment-index="4"}
$$
\CER(\bh) := \E{ \sqNorm{ \rfunc{X} - \bhyp{X} } } , 
\qquad
\boxed{
  \CER(\bh_{\DA+\ERM}) \leq \CER(\bh_{\ERM}) .
}
$$
:::
::: {.incremental  fragment-index="5"}
- Strictly better when DA perturbes spurious features correlated with $\xi$.
- But otherwise performs no worse than ERM.
:::
:::




## Data augmentation = relaxed IVs
::: {.row}
::: {.columns}
::: {.column width="60%"}

::: {.fragment fragment-index="1"}
**Key insight:** DA params $\gG$ are *IV-like (IVL)*[—having IV properties (i)—(iii) by design.]{.fragment fragment-index="2"}
:::

::: {.fragment fragment-index="3"}
<br>Such a relaxation renders IV regression [ill-posed]{.highlight}, [so we suggest *IVL regression*:]{.fragment fragment-index="4"}
:::

:::
::: {.column width="40%" .rightcol}
![](images/augmentation-intervention.svg){width=100% style="float:right;"}
:::
:::
:::
::: {.row}
::: {.fragment fragment-index="4"}
$$
R_{\IVL}(\bh) := R_{\IV}(\bh) + \boxed{\alpha \cdot R_{\ERM}(\bh)} \Big\} {\tiny\text{ERM regularizer for ill-posed IV reg.}}
$$
:::

::: {.fragment fragment-index="5"}
$\Rightarrow$ The composition DA+IVL simulates a *worst-case/adversarial* DA.
:::

::: {.fragment fragment-index="6"}
$\Rightarrow$ DA+IVL [dominates]{.highlight} DA+ERM; better iff spurious features perturbed,
$$
\boxed{\CER(\bh_{\DA+\IVL}) \leq \CER(\bh_{\DA+\ERM}).}
$$
:::

:::















## Data augmentation = causal regularization

::: {.fragment}
**Causal regularization:** Methods aim to impove causal estimation of $\rf$ even if full identification may not be possible.
:::

::: {.fragment}
[But why bother?]{.alert}
:::

::: {.incremental}
- **"No-regret" improvement:** Under our symmetry based DA construction, DA dominates on causal estimation $\Rightarrow$ sometimes better, [never worse]{.highlight}.
- **Robust prediction:** Mitigating confounding bias in the data reduces spurious correlations $\Rightarrow$ predictors generalize better to treatment [distribution shifts]{.highlight}.
:::

::: {.fragment}
$\Rightarrow$ Causal regularization is a principled approach for downstream tasks

- - *out-of-distribution (OOD) generalizaiton*
- - *domain generalizaiton*
:::


# Experiments

## Simulation ablations

::: {.fragment fragment-index="5"}
![](https://uzairakbar.github.io/causal-data-augmentation/sweep_plots.svg){width=100%}
:::

::: {.fragment fragment-index="1"}
Simulation experiment with a [linear, centered Gaussian model]{.highlight} [with $\rbf\in\R^m$,
*confounding strength* $\kappa > 0$, and *DA strength* $\gamma > 0$, s.t.]{.fragment fragment-index="2"}
[<br>$\qquad\qquad\qquad \gG X := X + \gamma\cdot \gG\qquad$  $\gG\in\operatorname{null}(\rbf)$.]{.fragment fragment-index="3"}
[<br>*Normalized CER (nCER)* $=0$  for true $\rf$ and $1$ for pure confounding.]{.fragment fragment-index="4"}
:::



## Baseline comparison

::: {.fragment fragment-index="2"}
![](https://uzairakbar.github.io/causal-data-augmentation/box_plots.svg){width=100%}
:::

::: {.fragment fragment-index="1"}
Comparison with select causal regularization methods and common domain generalisation baselines. All methods are provided only $(X, Y)$ data along with DA transformations $\gG$—Gausian noise in [optical device]{.highlight}, and hue, saturation, contrast, translation perturbations in [colored-MNIST]{.highlight}.
:::

## Conclusion

::: {.fragment fragment-index="3"}
![](images/table.svg){width=80%}
:::

::: {.fragment fragment-index="1"}
We provide a [unifying framework]{.highlight} b/w symmetry transformations and causal interventions, [allowing us to re-purpose the ubiquitous statistical regularization tool of data augmentation for causal regularization.]{.fragment fragment-index="2"}
:::


# Thank You

<i class="fa-brands fa-linkedin"></i> [in/uzair25](https://www.linkedin.com/in/uzair25/)

<i class="fa-brands fa-twitter-square"></i> [&#64;uzairakbar25](https://x.com/uzairakbar25/)

<i class="fa fa-file-text"></i> [arXiv:2510.25128](https://arxiv.org/abs/2510.25128)

::: {style="position: absolute; bottom: 0px; right: 25px;"}
[![Project Webpage](images/qr-code.svg){width=120}](https://uzairakbar.github.io/causal-data-augmentation/)
:::
